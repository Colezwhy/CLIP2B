# CLIP2B
The implementation fo CLIP2B, combining Language priorities with pointly supervised weak labels for high quality object detection.
It achieves +2.5mAP performance on VOC dataset on both years, which is closer to the fully supervised one, FasterRCNN with 69.9mAP, giving a hope that weakly supervised object detection can approach or even surpass fully supervised ones.
![image](https://github.com/Colezwhy/CLIP2B/blob/main/RES.png)
![image](https://github.com/Colezwhy/CLIP2B/blob/main/ppl.png)

# Acknoledgement
Thanks the authors of P2BNet for their wonderful codebase! 
